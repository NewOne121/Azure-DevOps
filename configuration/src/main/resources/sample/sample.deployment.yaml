databricks:
  baseUrl: '#{databricks_baseurl}#'
  connectionTimeout: 100000
  readTimeout: 100000
  debug: true
  clusterTimeout: 1000000
keyVault:
  url: '#{keyvault_url}#'
  tenantId: '#{keyvault_tenantId}#'
  clientId: '#{keyvault_clientId}#'
  clientSecret: '#{keyvault_clientSecret}#'
deployToken:
  token: !secret "ServiceToken"
  username: '#{databricks_username}#'
additionalTokens:

cluster:
  autoscale:
    min_workers: 1
    max_workers: 5
  spark_version: "6.2.x-scala2.11"
  node_type_id: "Standard_DS3_v2"
  cluster_name: '#{job_name}#-autodeploy-#{package.version}#-#{BUILD_BUILDNUMBER}#'
  spark_conf:
    - key: "spark.databricks.delta.preview.enabled"
      value: "true"
    - key: "spark.sql.hive.metastore.jars"
      value: "builtin"
    - key: "spark.sql.hive.metastore.version"
      value: "1.2.1"
  driver_node_type_id: "Standard_DS3_v2"
  init_scripts:
    - dbfs:
        destination: "dbfs:/script.sh"
  autotermination_minutes: 30
files:
  - from: '#{SYSTEM_DEFAULTWORKINGDIRECTORY}#/#{jar_name}#-#{package.version}#.jar'
    to: "/tmp/jars/#{jar_name}#-#{package.version}#.jar"
  - from: '#{AGENT_WORKFOLDER}#/_temp/#{config_file_name}#'
    to: "/tmp/taof/config/#{config_file_name}#"
jobs:
  - name: '#{job_name}#'
    timeout_seconds: 0
    spark_jar_task:
      main_class_name: '#{main_class_name}#'
      parameters:
        - "-c"
        - "/dbfs/tmp/taof/config/#{config_file_name}#"
    max_concurrent_runs: 1
    libraries:
      - jar: "dbfs:/tmp/jars/#{jar_name}#-#{package.version}#.jar"